trainer:
  gpus: 1
  max_epochs: 24
  precision: 16
  benchmark: true
  num_sanity_val_steps: 0
  weights_summary: full
#  log_gpu_memory: all

dataloaders:
  train:
    num_workers: 12
    batch_size: 512
  val:
    num_workers: 12
    batch_size: 4096
  test:
    num_workers: 12
    batch_size: 4096

dataset:
  data_path: "cifar10_experiment/data/cifar10"
  normalize:
    mean: [0.4914117647058824, 0.48215686274509806, 0.44654901960784316]  # after 0-1 norm
    std:  [0.24701960784313726, 0.2434901960784314, 0.2615686274509804]   # after 0-1 norm

data_transformations:
  pad:
    padding: 4
    fill: 0
    padding_mode: reflect
  crop:
    size: 32
  cutout:
    size: 8

optimizer:
  SGD:
    lr: 1
    weight_decay: 0.0005
    momentum: 0.9
    nesterov: true
  lr_scheduler:
    epochs:
      start: 0
      peek: 5
      end: -1   # using max_epochs from the trainer
    values:
      start: 0
      peek: 0.4
      end: 0

model:
  layers:
    layer_0:
      conv:
        in_channels: 3
        out_channels: 64
        kernel_size: 3
        stride: 1
        padding: 1
        bias: false
      batch_norm:
        num_features: 64
        eps: 0.00001
        momentum: 0.1
      relu:
        inplace: true

    layer_1:
      conv:
        in_channels: 64
        out_channels: 128
        kernel_size: 3
        stride: 1
        padding: 1
        bias: false
      batch_norm:
        num_features: 128
        eps: 0.00001
        momentum: 0.1
      relu:
        inplace: true
      max_pool:
        kernel_size: 2
        stride: 2

    layer_2:
      conv:
        in_channels: 128
        out_channels: 256
        kernel_size: 3
        stride: 1
        padding: 1
        bias: false
      batch_norm:
        num_features: 256
        eps: 0.00001
        momentum: 0.1
      relu:
        inplace: true
      max_pool:
        kernel_size: 2
        stride: 2

    layer_3:
      conv:
        in_channels: 256
        out_channels: 512
        kernel_size: 3
        stride: 1
        padding: 1
        bias: false
      batch_norm:
        num_features: 512
        eps: 0.00001
        momentum: 0.1
      relu:
        inplace: true
      max_pool:
        kernel_size: 2
        stride: 2

    final:
      max_pool:
        kernel_size: 4
        stride: null
      linear:
        in_features: 512
        out_features: 10
        bias: false
      scalar:
        weight: 0.125
